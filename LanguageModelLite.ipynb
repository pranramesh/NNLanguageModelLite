{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0733bee5",
   "metadata": {},
   "source": [
    "## Bigram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3100bf",
   "metadata": {},
   "source": [
    "The Bigram language model functions under a Markov assumption. The basic premise is that every letter has a probability distribution for what letters follow it, as well as whether it's at the beginning or ending of the name. It's a very simple Markov chain that chooses the next letter based on the letter immediately before it. We can randomly intialize a starting letter and build out the name from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705b98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc9668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"names.txt\", 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4b2930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0131268a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e m\n",
      "m m\n",
      "m a\n",
      "o l\n",
      "l i\n",
      "i v\n",
      "v i\n",
      "i a\n",
      "a v\n",
      "v a\n",
      "i s\n",
      "s a\n",
      "a b\n",
      "b e\n",
      "e l\n",
      "l l\n",
      "l a\n"
     ]
    }
   ],
   "source": [
    "for name in data[:4]:\n",
    "    for i in range(len(name) - 1):\n",
    "        print(name[i], name[i + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97385b9a",
   "metadata": {},
   "source": [
    "Creating a lookup table for characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e672cb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'a',\n",
       " 1: 'b',\n",
       " 2: 'c',\n",
       " 3: 'd',\n",
       " 4: 'e',\n",
       " 5: 'f',\n",
       " 6: 'g',\n",
       " 7: 'h',\n",
       " 8: 'i',\n",
       " 9: 'j',\n",
       " 10: 'k',\n",
       " 11: 'l',\n",
       " 12: 'm',\n",
       " 13: 'n',\n",
       " 14: 'o',\n",
       " 15: 'p',\n",
       " 16: 'q',\n",
       " 17: 'r',\n",
       " 18: 's',\n",
       " 19: 't',\n",
       " 20: 'u',\n",
       " 21: 'v',\n",
       " 22: 'w',\n",
       " 23: 'x',\n",
       " 24: 'y',\n",
       " 25: 'z',\n",
       " 26: '<S>',\n",
       " 27: '<E>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "stringtoint = {s:i for i,s in enumerate(chars)}\n",
    "stringtoint[\"<S>\"] = 26\n",
    "stringtoint[\"<E>\"] = 27\n",
    "inttostring = {i: s for i,s in enumerate(chars)}\n",
    "inttostring[26] = \"<S>\"\n",
    "inttostring[27] = \"<E>\"\n",
    "inttostring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367b65f",
   "metadata": {},
   "source": [
    "Creating a 2-d tensor/array which contains how often a letter is followed by another. For example, to see if \"a\" is followed by \"b\" we would look at counts[1, 2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee05371",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = torch.zeros((28,28), dtype=torch.int32)\n",
    "for name in data:\n",
    "    name_letters = [\"<S>\"] + list(name) + [\"<E>\"]\n",
    "    for letter1, letter2 in zip(name_letters, name_letters[1:]):\n",
    "        i1 = stringtoint[letter1]\n",
    "        i2 = stringtoint[letter2]\n",
    "        counts[i1, i2] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f44663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb8c88f58e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f064699f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 556,  541,  470, 1042,  692,  134,  168, 2332, 1650,  175,  568, 2528,\n",
       "        1634, 5438,   63,   82,   60, 3264, 1118,  687,  381,  834,  161,  182,\n",
       "        2050,  435,    0, 6640], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf95071",
   "metadata": {},
   "source": [
    "Creating probability mapping to sample bigrams from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bbc6192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0164, 0.0160, 0.0139, 0.0308, 0.0204, 0.0040, 0.0050, 0.0688, 0.0487,\n",
       "        0.0052, 0.0168, 0.0746, 0.0482, 0.1605, 0.0019, 0.0024, 0.0018, 0.0963,\n",
       "        0.0330, 0.0203, 0.0112, 0.0246, 0.0048, 0.0054, 0.0605, 0.0128, 0.0000,\n",
       "        0.1960])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_map = counts[0].float()\n",
    "probability_map /= probability_map.sum()\n",
    "probability_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0323d8",
   "metadata": {},
   "source": [
    "Example of sampling. We feed in the distribution created by the probability map and use torch.multinomial to sample from this given distribtuon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7118445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = torch.multinomial(probability_map, num_samples=1, replacement=True).item()\n",
    "inttostring[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d037535",
   "metadata": {},
   "source": [
    "For some efficiency and practice, notice that we are taking row-wise sums and dividing them constantly on each iteration. Note that keepdim=True. This allows for normalization across the rows. If we left it out, it would normalize the columns, because of broadcasting semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb15a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = counts.float()\n",
    "P /= P.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0cb359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ebbd8e",
   "metadata": {},
   "source": [
    "Establishing loop to create probability distribution for each letter. Also samples some names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a843ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le<E>\n",
      "al<E>\n",
      "gar<E>\n",
      "khth<E>\n",
      "maeie<E>\n",
      "mamaizi<E>\n",
      "shayszirla<E>\n",
      "tamon<E>\n",
      "erkan<E>\n",
      "yndoosk<E>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    idx = 26\n",
    "    out = []\n",
    "    while True:\n",
    "    \n",
    "        p = P[idx]\n",
    "        \n",
    "        #next index is randomly sampled from probability distribution from preceding letter\n",
    "        idx = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        out.append(inttostring[idx])\n",
    "        if idx == 27:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e727a0c",
   "metadata": {},
   "source": [
    "We will now incorporate the idea of loss into our model. We will do this by using log likelihood (ie we take the product of all probabilities output from our model and then compare it with that of our training set. if it's close to 0, thats good if its more negative then that's bad). To follow the semantics of loss (where less is better), we will minimize the negative log likelihood. For the sake of this bigram model we can just evaluate the quality of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31cfaa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4541)\n"
     ]
    }
   ],
   "source": [
    "ll = 0.0\n",
    "n = 0\n",
    "\n",
    "for name in data:\n",
    "    name_letters = [\"<S>\"] + list(name) + [\"<E>\"]\n",
    "    for letter1, letter2 in zip(name_letters, name_letters[1:]):\n",
    "        i1 = stringtoint[letter1]\n",
    "        i2 = stringtoint[letter2]\n",
    "        prob = P[i1, i2]\n",
    "        log_prob = torch.log(prob)\n",
    "        ll += log_prob\n",
    "        n +=1\n",
    "\n",
    "nll = -1 * ll\n",
    "average_neg_log_likelihood = nll/n\n",
    "print(average_neg_log_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fead2e",
   "metadata": {},
   "source": [
    "## Part 2: Basic Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c3245",
   "metadata": {},
   "source": [
    "We will be using a basic neural network and gradient based optimization rather than markov assumptions to come to a similar name generation state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206192ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a training set with inputs and outputs. Keep in mind that the input to the neural network will be a single character and the output will be the probability distribution that the subsequent character will be chosen from.\n",
    "\n",
    "x, y = [], []\n",
    "for name in data:\n",
    "    name_letters = [\"<S>\"] + list(name) + [\"<E>\"]\n",
    "    for letter1, letter2 in zip(name_letters, name_letters[1:]):\n",
    "        i1 = stringtoint[letter1]\n",
    "        i2 = stringtoint[letter2]\n",
    "        x.append(i1)\n",
    "        y.append(i2)\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b69603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26,  4, 12,  ..., 24, 25, 23])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd4d37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 12, 12,  ..., 25, 23, 27])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f293e0",
   "metadata": {},
   "source": [
    "We will need to do one hot encoding on the input to make is \"passable\" into a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9406c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45aa0ad",
   "metadata": {},
   "source": [
    "Based on the gradient descent algorithm, we run 10 iterations to try and minimize our negative log likelihood loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b68d2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((28, 28), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7152162f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4937784671783447\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    x_encoded = F.one_hot(x, num_classes=28).float()\n",
    "    logits = x_encoded @ W\n",
    "\n",
    "    #Forward pass. the following two lines specifically are a manual representation of the soft-max activation function\n",
    "    pseudo_counts = logits.exp()\n",
    "    probs = pseudo_counts / pseudo_counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(228146), y].log().mean() + 0.01*(W**2).mean() #the added on part of loss is regularization (smoothing out the probability distribution)\n",
    "\n",
    "    #backward pass\n",
    "    W.grad = None # sets gradients to 0\n",
    "    loss.backward()\n",
    "    #manual update\n",
    "    W.data += -50 * W.grad\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94091f5b",
   "metadata": {},
   "source": [
    "The biggest advantage of the neural net over its bigram counterpart is the scalability. Adding another layer of complexity to the bigram model by \"adding memory\" (ie changing how many letters are taken into consideration to determine the next layer) becomes a bottleneck. However, for neural networks, we can scale up and add complexity relatively easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15fe721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arja<E>\n",
      "grra<E>\n",
      "wahrn<E>\n",
      "<E>\n",
      "nato<E>\n"
     ]
    }
   ],
   "source": [
    "#sampling from our neural net\n",
    "\n",
    "for i in range(5):\n",
    "    out=[]\n",
    "    index = 26\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([index]), num_classes=28).float()\n",
    "        logits = xenc @ W\n",
    "        coun = logits.exp()\n",
    "        p = coun/coun.sum(1, keepdims=True)\n",
    "        \n",
    "        index = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        out.append(inttostring[index])\n",
    "        if index == 27:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00241c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
